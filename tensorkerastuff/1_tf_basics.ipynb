{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prova](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/TensorFlow_logo.svg/1200px-TensorFlow_logo.svg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.16.1)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.7)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.25.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: optree in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\giord\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Manipulation Basics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Creation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 0-dimensional tensor is a __scalar__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = tf.constant(0)\n",
    "print(f\"Value of the tensor = {scalar}\")\n",
    "print(f\"Number of dimensions = {len(scalar.shape)}\")\n",
    "print(f\"Tensor's shape = {scalar.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 1-dimensional tensor is a __vector__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = tf.constant([1, 2, 3])\n",
    "print(f\"Value of the tensor = {vector}\")\n",
    "print(f\"Number of dimensions = {len(vector.shape)}\")\n",
    "print(f\"Tensor's shape = {vector.shape}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 2-dimensional tensor is a __matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = tf.constant(\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]]\n",
    ")\n",
    "print(f\"Value of the tensor = \\n {matrix}\")\n",
    "print(f\"Number of dimensions = {len(matrix.shape)}\")\n",
    "print(f\"Tensor's shape = {matrix.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generalize tensors to __n dimensions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "tensor = tf.random.normal(tuple(3 for _ in range(n)))\n",
    "print(f\"Value of the tensor = \\n {tensor}\")\n",
    "print(f\"Number of dimensions = {len(tensor.shape)}\")\n",
    "print(f\"Tensor's shape = {tensor.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each tensor is characterized also by a __data type__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which can be cast to others (with the clear consequences on the numerical representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_tensor = tf.cast(tensor, dtype=tf.int32)\n",
    "print(int_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor indexing e slicing\n",
    "\n",
    "Tensors can be __indexed__ (i.e., ``tensor[i, :, :]``) or __sliced__ (i.e., ``tensor[:i, ...]``)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing a tensor reduces its dimensionality depending to the number of \"free\" dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Scalar = {tensor[0, 1, 0]}\")\n",
    "print(f\"Vector = {tensor[:, 0, -1]}\") # : means all elements in that dimension\n",
    "print(f\"Matrix = {tensor[:, 2]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing reduces the size of the sliced dimension. With this approach, only contiguous slices can be taken. To get scattered slices, use [``tf.gather``](https://www.tensorflow.org/api_docs/python/tf/gather)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_slice = tensor[1:]\n",
    "print(f\"tensor_slice = {tensor_slice}\")\n",
    "print(f\"Shape of tensor_slice = {tensor_slice.shape}\")\n",
    "print(f\"Number of dimensions = {len(tensor_slice.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_slice = tensor[1:, :, -1:]\n",
    "print(f\"tensor_slice = {tensor_slice}\")\n",
    "print(f\"Shape of tensor_slice = {tensor_slice.shape}\")\n",
    "print(f\"Number of dimensions = {len(tensor_slice.shape)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing and slicing can be also mixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_slice = tensor[1:, :, 2]\n",
    "print(f\"tensor_slice = {tensor_slice}\")\n",
    "print(f\"Shape of tensor_slice = {tensor_slice.shape}\")\n",
    "print(f\"Number of dimensions = {len(tensor_slice.shape)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat and stack\n",
    "\n",
    "- ``tf.concat``: concatenates n tensors on the `axis` dimension. All the dimensions of the input tensors, except for the `axis` dimension, must match.\n",
    "- ``tf.stack``: stacks n tensors on the `axis` dimension, which is added for the resulting tensor. All the dimensions of the input tensors must match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = tf.random.normal((2, 3, 4))\n",
    "tensor_2 = tf.random.uniform((2, 6, 4))\n",
    "concat_tensor = tf.concat([tensor_1, tensor_2], axis=1)\n",
    "print(f\"Shape = {concat_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_2 = tf.random.uniform((2, 3, 4))\n",
    "stacked_tensor = tf.stack([tensor_1, tensor_2], axis=1)\n",
    "print(f\"Shape = {stacked_tensor.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn!\n",
    "\n",
    "1. Create a tensor with random numbers of shape (2, 5, 3);\n",
    "2. Get the last element on dimension 1;\n",
    "3. Put it at the beginning of dimension 1.\n",
    "\n",
    "_Note_: use the placeholders on the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 5, 3)\n",
      "(1, 5, 3)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "init_tensor = tf.random.normal((2, 5, 3))\n",
    "\n",
    "concatenated_tensor = tf.concat([init_tensor[:,-1:], init_tensor[:,:-1]], axis=1)\n",
    "\n",
    "final_tensor = concatenated_tensor\n",
    "\n",
    "print(concatenated_tensor.shape)\n",
    "print(init_tensor[0:-1].shape)\n",
    "print(init_tensor[:,-1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good job!\n"
     ]
    }
   ],
   "source": [
    "if final_tensor.shape == (2, 5, 3):\n",
    "    if tf.reduce_all(final_tensor[:, 0] == init_tensor[:, -1]):\n",
    "        print(\"Good job!\")\n",
    "    else:\n",
    "        print(\"Mh, correct dimensions but wrong values\")\n",
    "else:\n",
    "    print(f\"Wrong, dimensions are {init_tensor.shape} and {final_tensor.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor operations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``+, *, /, -`` are overloaded to support tensor operations. All the operations are element-wise, support broadcasting for the non-matching dimensions (i.e., (2, 1, 2) + (2, 3, 2) --> (2, 3, 2))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 5.7775062e-01 -6.5254176e-01  1.7484516e+00]\n",
      "  [-1.7979014e+00 -1.0387663e+00 -1.7029886e+00]\n",
      "  [ 1.6585844e+00 -3.6904830e-01  2.6468055e+00]]\n",
      "\n",
      " [[-4.8274630e-01  9.6702838e-01  2.5442308e-01]\n",
      "  [-8.0187869e-01 -1.1872365e+00  2.3087339e-01]\n",
      "  [-2.2844857e-01  1.3941286e+00 -2.0409700e-01]]\n",
      "\n",
      " [[ 9.6786220e-04 -1.1324750e+00  1.9334199e+00]\n",
      "  [ 1.1588806e+00  1.9063296e+00  3.5823819e-01]\n",
      "  [-6.4184725e-01  7.2523594e-01 -4.5922977e-01]]], shape=(3, 3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.random.normal((3, 3, 3))\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 3), dtype=float32, numpy=\n",
       "array([[[ 1.5777507 ,  0.34745824,  2.7484517 ],\n",
       "        [-0.7979014 , -0.03876626, -0.7029886 ],\n",
       "        [ 2.6585844 ,  0.6309517 ,  3.6468055 ]],\n",
       "\n",
       "       [[ 0.5172537 ,  1.9670284 ,  1.2544231 ],\n",
       "        [ 0.19812131, -0.18723655,  1.2308733 ],\n",
       "        [ 0.77155143,  2.3941286 ,  0.79590297]],\n",
       "\n",
       "       [[ 1.0009679 , -0.13247502,  2.93342   ],\n",
       "        [ 2.1588807 ,  2.9063296 ,  1.3582382 ],\n",
       "        [ 0.35815275,  1.7252359 ,  0.54077023]]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = tf.random.normal((3, 2))\n",
    "tensor_2 = tf.random.normal((3, 2))\n",
    "tensor_1 + tensor_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`@` defines the dot product between two tensors. The inner dimensions must match the criterion for the dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 @ tf.transpose(tensor_2, [1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = tf.random.normal((10, 3, 2))\n",
    "tensor_2 = tf.random.normal((10, 3, 2))\n",
    "tensor_1 @ tf.transpose(tensor_2, [0, 2, 1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning with TensorFlow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digit Classification with a Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = tf.keras.datasets.mnist.load_data(path='ds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Label is {train_y[0]}\")\n",
    "Image.fromarray(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images need to be flattened to be taken as input by a linear classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = tf.reshape(train_x, [train_x.shape[0], -1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to __rescale__ the values to the interval [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x / 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the linear model requires only a weight matrix and a bias vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b = tf.Variable(tf.random.normal((784, 10))), tf.Variable(tf.zeros(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = tf.nn.softmax(train_x @ W + b, axis=-1)\n",
    "prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our linear model, let's define the tools for the optimization, i.e., __the optimizer and the loss function__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-1)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A training loop with TensorFlow is shaped as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "epochs = 500 \n",
    "\n",
    "for e in range(epochs):\n",
    "    # The GradientTape context records every operation applied to tensors\n",
    "    # inside the context. The tape can then be used to compute the gradient\n",
    "    # of a computation with respect to the tensors it has \"watched\".\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = tf.nn.softmax(train_x @ W + b, axis=-1)\n",
    "        loss_value = loss_fn(train_y, prediction)\n",
    "    \n",
    "    # We compute the gradient of the loss with respect to the parameters\n",
    "    # of the model\n",
    "    grads = tape.gradient(loss_value, [W, b])\n",
    "\n",
    "    # We apply the gradient to the parameters of the model\n",
    "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
    "\n",
    "    # We print the loss every 20 epochs\n",
    "    prediction = tf.nn.softmax(train_x @ W + b, axis=-1)\n",
    "    if e % 20 == 0:\n",
    "        print(f\"Epoch {e}: accuracy = {accuracy_score(train_y, tf.argmax(prediction, axis=-1))}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, if we use Adam as optimization approach, the performance in the learning phase increases dramatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b = tf.Variable(tf.random.normal((784, 10))), tf.Variable(tf.zeros(10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "for e in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = tf.nn.softmax(train_x @ W + b, axis=-1)\n",
    "        loss_value = loss_fn(train_y, prediction)\n",
    "    \n",
    "    grads = tape.gradient(loss_value, [W, b])\n",
    "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
    "\n",
    "    if e % 20 == 0:\n",
    "        prediction = tf.nn.softmax(train_x @ W + b, axis=-1)\n",
    "        print(f\"Epoca {e}: accuratezza = {accuracy_score(train_y, tf.argmax(prediction, axis=-1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to implement your own training loop with a linear regression on the Boston Housing dataset. \n",
    "\n",
    "Notes:\n",
    "1. It is a regression problem, so you need to use a different loss function;\n",
    "2. MinMax Scaling may not be the most appropriate way to rescale the input features (maybe sklearn's StandardScaler?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57026/57026\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "(train_x, train_y), _ = tf.keras.datasets.boston_housing.load_data(\"./ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "W, b = tf.Variable(tf.random.normal(train_x.shape)), tf.Variable(tf.zeros(train_x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped____MklMatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [404,13], In[1]: [404,13] [Op:MatMul] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# The GradientTape context records every operation applied to tensors\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# inside the context. The tape can then be used to compute the gradient\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# of a computation with respect to the tensors it has \"watched\".\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m----> 9\u001b[0m         prediction \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_x\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b\n\u001b[0;32m     10\u001b[0m         loss_value \u001b[38;5;241m=\u001b[39m loss_fn(train_y, prediction)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# We compute the gradient of the loss with respect to the parameters\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# of the model\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tensorflow\\python\\framework\\ops.py:5983\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5981\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   5982\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 5983\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped____MklMatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [404,13], In[1]: [404,13] [Op:MatMul] name: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "epochs = 500 \n",
    "\n",
    "for e in range(epochs):\n",
    "    # The GradientTape context records every operation applied to tensors\n",
    "    # inside the context. The tape can then be used to compute the gradient\n",
    "    # of a computation with respect to the tensors it has \"watched\".\n",
    "    with tf.GradientTape() as tape:\n",
    "        prediction = train_x @ W + b # 'chin lernin model\n",
    "        loss_value = loss_fn(train_y, prediction)\n",
    "    \n",
    "    # We compute the gradient of the loss with respect to the parameters\n",
    "    # of the model\n",
    "    grads = tape.gradient(loss_value, [W, b])\n",
    "\n",
    "    # We apply the gradient to the parameters of the model\n",
    "    optimizer.apply_gradients(zip(grads, [W, b]))\n",
    "\n",
    "    # We print the loss every 20 epochs\n",
    "    prediction = tf.nn.softmax(train_x @ W + b, axis=-1)\n",
    "    if e % 20 == 0:\n",
    "        print(f\"Epoch {e}: accuracy = {mean_squared_error(train_y, prediction)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf_mela')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3917c018cfd92834e25e8ac39593c8ba50cba5d103d91e5ca7d5a867c45ae1af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
